{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercice 1 MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrPxsBqyXGD2"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import torchvision.datasets as datasets\r\n",
        "from torchvision.utils import make_grid\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg5gi0aSXIlO"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\r\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3rrvYDqXNnK"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channels, out_channels):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        \r\n",
        "        self.conv1 = nn.Conv2d(in_channels  ,  in_channels*2, 5)\r\n",
        "        self.conv2 = nn.Conv2d(in_channels*2, out_channels  , 5)\r\n",
        "        \r\n",
        "        self.activation = nn.ReLU()\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.activation(x)\r\n",
        "\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.activation(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRxbxUu8XUKn"
      },
      "source": [
        "class VectorQuantizer(nn.Module):\r\n",
        "    def __init__(self, num_codewords, codewords_dim, commitment_cost):\r\n",
        "        super(VectorQuantizer, self).__init__()\r\n",
        "        \r\n",
        "        self.num_codewords = num_codewords\r\n",
        "        self.codewords_dim = codewords_dim\r\n",
        "        self.codewords = nn.Parameter(torch.rand(self.num_codewords, self.codewords_dim),requires_grad=True)\r\n",
        "\r\n",
        "        self.commitment_cost = commitment_cost\r\n",
        "        \r\n",
        "    def forward(self, inputs):\r\n",
        "        # Reshape: B, C, H, W -> B*H*W, C\r\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\r\n",
        "        flat_inputs = inputs.view(-1, self.codewords_dim)\r\n",
        "\r\n",
        "        # Calculating distances:\r\n",
        "        distances = torch.pow(flat_inputs.unsqueeze(1) - self.codewords.unsqueeze(0),2).sum(2)\r\n",
        "\r\n",
        "        # Argmin:\r\n",
        "        encoding_indices = torch.argmin(distances, dim=1)\r\n",
        "\r\n",
        "        # Index from dictionary:\r\n",
        "        # quantized[i,j] = self.codewords[encoding_indices[i,j], j]\r\n",
        "        quantized = torch.gather(self.codewords,0,encoding_indices.unsqueeze(1).expand(-1, self.codewords_dim)).view(inputs.shape)\r\n",
        "        encoding_indices = encoding_indices.view(inputs.shape[:-1])\r\n",
        "\r\n",
        "        # quantization loss\r\n",
        "        quantizing_loss = F.mse_loss(quantized.detach(), inputs)\r\n",
        "        commitment_loss = F.mse_loss(quantized, inputs.detach())\r\n",
        "        loss = quantizing_loss + self.commitment_cost * commitment_loss\r\n",
        "\r\n",
        "        # magic trick to copy gradients from inputs\r\n",
        "        quantized = inputs + (quantized - inputs).detach()\r\n",
        "        \r\n",
        "        #Reshape:\r\n",
        "        return quantized.permute(0, 3, 1, 2), encoding_indices, loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onn25KooXR14"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, in_channels, out_channels):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=5)\r\n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels//2, out_channels, kernel_size=5)\r\n",
        "\r\n",
        "        self.activation = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        x = self.conv1(inputs)\r\n",
        "        x = self.activation(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcCpwTEGXWx4"
      },
      "source": [
        "class VQVAE(nn.Module):\r\n",
        "    def __init__(self,x_dim,z_dim,num_codewords,commitment_cost):\r\n",
        "        super().__init__()\r\n",
        "        self.encoder = Encoder(x_dim,z_dim)\r\n",
        "        self.quantizer = VectorQuantizer(num_codewords, z_dim, commitment_cost)\r\n",
        "        self.decoder = Decoder(z_dim, x_dim)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        z_e = self.encoder(x)\r\n",
        "        z_q, codes, q_loss = self.quantizer(z_e)\r\n",
        "        x_hat = self.decoder(z_q)\r\n",
        "        \r\n",
        "        return x_hat, codes, q_loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxJe5ZYTXgtr"
      },
      "source": [
        "#initialize input (limited to the first 1000 values)\r\n",
        "input = mnist_trainset.data.unsqueeze(1).float()[:10000]\r\n",
        "\r\n",
        "#construction target\r\n",
        "target = torch.zeros(len(input),10)\r\n",
        "value = mnist_trainset.targets[:len(input)]\r\n",
        "for ind in range(len(target)):\r\n",
        "    target[ind,value[ind]] = 1\r\n",
        "    \r\n",
        "#data loader\r\n",
        "dataloader = torch.utils.data.DataLoader(input, batch_size = 32)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duTpiqcmXjLc"
      },
      "source": [
        "learning_rate = 0.01\r\n",
        "\r\n",
        "model = VQVAE(1,16,10,0.15).to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters() , lr=learning_rate, amsgrad=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "3kgQAwgjXlxn",
        "outputId": "720fa893-cb64-4a7e-8135-0d52e5f7e888"
      },
      "source": [
        "for epoch in range(100):\r\n",
        "    for x in dataloader:\r\n",
        "        x = x.to(device)\r\n",
        "        x_hat, codes, q_loss = model.forward(x)\r\n",
        "        \r\n",
        "        #calcul loss\r\n",
        "        rec_loss = F.mse_loss(x_hat, x)\r\n",
        "        loss = rec_loss + q_loss\r\n",
        "\r\n",
        "        #backprop\r\n",
        "        model.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        #optimizer.step()\r\n",
        "        \r\n",
        "        for f in (model.parameters()):\r\n",
        "            f.data.sub_(f.grad.data * learning_rate)\r\n",
        "        \r\n",
        "\r\n",
        "    print('Epoch {}: loss = {}'.format(epoch,loss.item()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss = 6335.32568359375\n",
            "Epoch 1: loss = 6334.9462890625\n",
            "Epoch 2: loss = 6334.92919921875\n",
            "Epoch 3: loss = 6334.91552734375\n",
            "Epoch 4: loss = 6334.9033203125\n",
            "Epoch 5: loss = 6334.89208984375\n",
            "Epoch 6: loss = 6334.88232421875\n",
            "Epoch 7: loss = 6334.8740234375\n",
            "Epoch 8: loss = 6334.8662109375\n",
            "Epoch 9: loss = 6334.859375\n",
            "Epoch 10: loss = 6334.853515625\n",
            "Epoch 11: loss = 6334.84814453125\n",
            "Epoch 12: loss = 6334.84326171875\n",
            "Epoch 13: loss = 6334.8388671875\n",
            "Epoch 14: loss = 6334.8349609375\n",
            "Epoch 15: loss = 6334.83154296875\n",
            "Epoch 16: loss = 6334.82861328125\n",
            "Epoch 17: loss = 6334.826171875\n",
            "Epoch 18: loss = 6334.82373046875\n",
            "Epoch 19: loss = 6334.82177734375\n",
            "Epoch 20: loss = 6334.81982421875\n",
            "Epoch 21: loss = 6334.81787109375\n",
            "Epoch 22: loss = 6334.81640625\n",
            "Epoch 23: loss = 6334.8154296875\n",
            "Epoch 24: loss = 6334.81396484375\n",
            "Epoch 25: loss = 6334.81298828125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bde0fd205f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42EFEj2LcKUg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}