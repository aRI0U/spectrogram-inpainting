{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yvan\\anaconda3\\lib\\site-packages\\torchaudio\\extension\\extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n",
      "C:\\Users\\Yvan\\anaconda3\\lib\\site-packages\\torchaudio\\backend\\utils.py:63: UserWarning: The interface of \"soundfile\" backend is planned to change in 0.8.0 to match that of \"sox_io\" backend and the current interface will be removed in 0.9.0. To use the new interface, do `torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False` before setting the backend to \"soundfile\". Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yvan\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchaudio\n",
    "import scipy.io.wavfile as wavfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "class NSynthDataset(data.Dataset):\n",
    "    def __init__(self, data_dir, **dl_kwargs):\n",
    "        self.data_dir = data_dir\n",
    "        self.dict = json.load(open(self.data_dir + \"examples.json\"))\n",
    "        self.filenames = list(self.dict.keys())\n",
    "        \n",
    "    def filter_instrument(self,inst_str):\n",
    "        new_dict = self.dict.copy()\n",
    "        for key in self.dict.keys():\n",
    "            if inst_str not in self.dict[key][\"instrument_str\"]:\n",
    "                new_dict.pop(key)\n",
    "        self.dict = new_dict.copy()\n",
    "        self.filenames = list(self.dict.keys())\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name = self.filenames[index]\n",
    "        sample, _ = torchaudio.load(self.data_dir + 'audio/{}.wav'.format(name))\n",
    "\n",
    "        Nwin = 512\n",
    "        spec = torchaudio.functional.spectrogram(sample.view(-1),0,torch.hann_window(Nwin),Nwin,int(Nwin/2),Nwin,None,True)\n",
    "        spec = torch.sqrt(torch.sum(spec**2,axis=2)) #valeur absolue\n",
    "        \n",
    "        return spec.unsqueeze(0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsynth_data = NSynthDataset(data_dir = \"./data/NSynth/nsynth-test/\")\n",
    "nsynth_data.filter_instrument(\"keyboard\")\n",
    "\n",
    "\n",
    "batch_size_train = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(nsynth_data,batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbatch_size_train = 32\\nbatch_size_test  = 32\\ntrain_loader = torch.utils.data.DataLoader(\\n    datasets.MNIST('/files/', train=True, download=True,\\n                            transform=transforms.Compose([\\n                            transforms.ToTensor()\\n                            ])),\\n                    batch_size=batch_size_train, shuffle=True)\\n\\ntest_loader = torch.utils.data.DataLoader(\\n    datasets.MNIST('/files/', train=False, download=True,\\n                            transform=transforms.Compose([\\n                            transforms.ToTensor()\\n                            ])),\\n                    batch_size=batch_size_test, shuffle=True)\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "batch_size_train = 32\n",
    "batch_size_test  = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/files/', train=True, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                            ])),\n",
    "                    batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/files/', train=False, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                            ])),\n",
    "                    batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels  ,  in_channels*2, 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels*2, out_channels  , 5)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_codewords, codewords_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self.num_codewords = num_codewords\n",
    "        self.codewords_dim = codewords_dim\n",
    "        self.codewords = nn.Parameter(torch.rand(self.num_codewords, self.codewords_dim),requires_grad=True)\n",
    "\n",
    "        self.commitment_cost = commitment_cost\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Reshape: B, C, H, W -> B*H*W, C\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        flat_inputs = inputs.view(-1, self.codewords_dim)\n",
    "\n",
    "        # Calculating distances:\n",
    "        distances = torch.pow(flat_inputs.unsqueeze(1) - self.codewords.unsqueeze(0),2).sum(2)\n",
    "\n",
    "        # Argmin:\n",
    "        encoding_indices = torch.argmin(distances, dim=1)\n",
    "\n",
    "        # Index from dictionary:\n",
    "        # quantized[i,j] = self.codewords[encoding_indices[i,j], j]\n",
    "        quantized = torch.gather(self.codewords,0,encoding_indices.unsqueeze(1).expand(-1, self.codewords_dim)).view(inputs.shape)\n",
    "        encoding_indices = encoding_indices.view(inputs.shape[:-1])\n",
    "\n",
    "        # quantization loss\n",
    "        quantizing_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        commitment_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = quantizing_loss + self.commitment_cost * commitment_loss\n",
    "\n",
    "        # magic trick to copy gradients from inputs\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        \n",
    "        #Reshape:\n",
    "        return quantized.permute(0, 3, 1, 2), encoding_indices, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=5)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels//2, out_channels, kernel_size=5)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self,x_dim,z_dim,num_codewords,commitment_cost):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(x_dim,z_dim)\n",
    "        self.quantizer = VectorQuantizer(num_codewords, z_dim, commitment_cost)\n",
    "        self.decoder = Decoder(z_dim, x_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_e = self.encoder(x)\n",
    "        z_q, codes, q_loss = self.quantizer(z_e)\n",
    "        x_hat = self.decoder(z_q)\n",
    "        \n",
    "        return x_hat, codes, q_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "network = VQVAE(1,16,10,0.15).to(device)\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "\n",
    "n_epochs = 5\n",
    "# Keep track of loss evolution for the train and the test dataset\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 256\n",
    "\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output, codes, q_loss = network(data)\n",
    "        \n",
    "        #calcul loss\n",
    "        rec_loss = F.mse_loss(output, data)\n",
    "        loss = rec_loss + q_loss\n",
    "\n",
    "        #backprop\n",
    "        network.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for f in (network.parameters()):\n",
    "            f.data.sub_(f.grad.data * learning_rate)\n",
    "            \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{:5}/{} ({:3}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                int(100. * batch_idx / len(train_loader)), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yvan\\anaconda3\\lib\\site-packages\\torch\\functional.py:515: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  ..\\aten\\src\\ATen\\native\\SpectralOps.cpp:653.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n",
      "C:\\Users\\Yvan\\anaconda3\\lib\\site-packages\\torch\\functional.py:515: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  ..\\aten\\src\\ATen\\native\\SpectralOps.cpp:590.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [    0/766 (  0%)]\tLoss: 0.256881\n",
      "Train Epoch: 2 [    0/766 (  0%)]\tLoss: 0.224402\n",
      "Train Epoch: 3 [    0/766 (  0%)]\tLoss: 0.208209\n",
      "Train Epoch: 4 [    0/766 (  0%)]\tLoss: 0.175503\n",
      "Train Epoch: 5 [    0/766 (  0%)]\tLoss: 0.144230\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,n_epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, data = next(examples)\n",
    "\n",
    "output, codes, q_loss = network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(data.detach().numpy()[i][0], cmap='gray', interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(output.detach().numpy()[i][0], cmap='gray', interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
