{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DeconvModel(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "        Creates a parametric DeconvNet model for the decoder.\n",
    "\n",
    "        The model has the following architecture:\n",
    "\n",
    "        One dense layer per element of parameter dense_layers:\n",
    "            - # of neurons given by the item in dense_layers\n",
    "            - each layer is followedby activation dense_activation\n",
    "\n",
    "        One convolution transpose layer per element of parameter conv_channels:\n",
    "            - # of channels given by the item in conv_channels\n",
    "            - each convolution is followed by activation conv_activation\n",
    "            - UpsamplingNearest2d between each pair of convolutions\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "\n",
    "        # the dimension of the input pictures and\n",
    "        # of the expected output latent variable\n",
    "        # (default values correspond to MNIST)\n",
    "        input_dim=10,        \n",
    "        output_height=28, \n",
    "        output_width=28,\n",
    "        output_channels=1,\n",
    "\n",
    "        # architecture of the conv and dense layers\n",
    "        dense_layers=None,\n",
    "        conv_channels=None, \n",
    "        conv_kernel=3,\n",
    "        upsample_factor=2,\n",
    "\n",
    "        # internal activation layers\n",
    "        dense_activation='ReLU',\n",
    "        conv_activation='ReLU'\n",
    "    ):\n",
    "        \n",
    "        # nn.Module instantiate\n",
    "        super().__init__()\n",
    "\n",
    "        # store useful parameters\n",
    "        self._input = input_dim\n",
    "\n",
    "        # find the dimensions of the first convolution\n",
    "        conv_dimensions = [(output_height, output_width)]\n",
    "        height, width = output_height, output_width\n",
    "        for i in range(len(conv_channels or []) - 1):\n",
    "            height = height // upsample_factor ** 2\n",
    "            width = width // upsample_factor ** 2\n",
    "            conv_dimensions.append((height, width))\n",
    "        conv_dimensions.reverse()\n",
    "        self._conv_in = (output_channels if conv_channels is None else conv_channels[0], *conv_dimensions[0])\n",
    "\n",
    "\n",
    "        # list linear layers\n",
    "        dense_sequence = []\n",
    "        widths = [input_dim] + (dense_layers or [])\n",
    "        for i in range(1, len(widths)):\n",
    "\n",
    "            # add a dense layer and activation\n",
    "            dense_sequence.append(nn.Linear(widths[i-1], widths[i]))\n",
    "            dense_sequence.append(eval(f'nn.{dense_activation}()'))\n",
    "\n",
    "        # create the last layer\n",
    "        dense_sequence.append(nn.Linear(widths[-1], self._conv_in[0] * self._conv_in[1] * self._conv_in[2]))\n",
    "\n",
    "\n",
    "        # list convolution layers\n",
    "        conv_sequence = []\n",
    "        if conv_channels:\n",
    "            channels = conv_channels + [output_channels]\n",
    "            for i in range(1, len(channels)):\n",
    "                \n",
    "                # add a convolution layer\n",
    "                conv_sequence.append(nn.ConvTranspose2d(\n",
    "                    in_channels=channels[i-1],\n",
    "                    out_channels=channels[i],\n",
    "                    kernel_size=conv_kernel,\n",
    "                    padding=int(conv_kernel // 2)  # keeps the size as 'same'\n",
    "                ))\n",
    "                \n",
    "                # add an activation  \n",
    "                conv_sequence.append(eval(f'nn.{conv_activation}()'))\n",
    "\n",
    "                # add upsampling\n",
    "                if i < len(channels) - 1:\n",
    "                    conv_sequence.append(nn.UpsamplingNearest2d(size=conv_dimensions[i]))\n",
    "\n",
    "\n",
    "        # put layers in sequential objects for use in self.forward()\n",
    "        self.conv = nn.Sequential(*conv_sequence)\n",
    "        self.dense = nn.Sequential(*dense_sequence)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "                    \n",
    "        # format for dense layers\n",
    "        x = inputs.view(-1, self._input)\n",
    "        \n",
    "        # apply dense layers if any\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        # format for convolutions\n",
    "        x = x.view(-1, *self._conv_in)\n",
    "        \n",
    "        # apply convolutions if any\n",
    "        outputs = self.conv(x)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=200, out_features=1750, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): ConvTranspose2d(10, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): UpsamplingNearest2d(size=(100, 28), mode=nearest)\n",
      "  (3): ConvTranspose2d(50, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "c = DeconvModel(dense_layers=[100, 200], conv_channels=[10, 50], output_height=100, output_channels=5)\n",
    "print(c.dense)\n",
    "print(c.conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand((5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 100, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(A).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
